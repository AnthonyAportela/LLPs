{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import hist as hs\n",
    "from coffea import processor, hist as chs\n",
    "from coffea.nanoevents.methods import vector, candidate\n",
    "from numba import jit\n",
    "\n",
    "from coffea.nanoevents import BaseSchema\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LLP_ntuple_processor(processor.ProcessorABC):\n",
    "    \"\"\"\n",
    "    This class is used to process the ntuples created by the LLP ntuple producer.\n",
    "    \"\"\"\n",
    "    \n",
    "    '''def cscCutter(self, events, cut): # i hate this.\n",
    "        if events.metadata['dataset'] == 'signal':\n",
    "            events.cscRechitCluster_match_gLLP_deltaR = events.cscRechitCluster_match_gLLP_deltaR[cut]\n",
    "        \n",
    "        if events.metadata['dataset'] == 'background':   \n",
    "            events.cscRechitCluster_match_cluster_index = events.cscRechitCluster_match_cluster_index[cut]\n",
    "            events.cscRechitCluster_match_cluster_dR = events.cscRechitCluster_match_cluster_dR[cut]    \n",
    "    \n",
    "        events.cscRechitClusterEtaSpread = events.cscRechitClusterEtaSpread[cut]\n",
    "        events.cscRechitClusterSize = events.cscRechitClusterSize[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus21 = events.cscRechitClusterNRechitChamberPlus21[cut]\n",
    "        events.cscRechitClusterAvgStation10perc = events.cscRechitClusterAvgStation10perc[cut]\n",
    "        events.cscRechitClusterYSpread = events.cscRechitClusterYSpread[cut]\n",
    "        events.cscRechitClusterNStation10perc = events.cscRechitClusterNStation10perc[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus11 = events.cscRechitClusterNRechitChamberMinus11[cut]\n",
    "        events.cscRechitClusterMe12Ratio = events.cscRechitClusterMe12Ratio[cut]\n",
    "        events.cscRechitClusterMe11Ratio = events.cscRechitClusterMe11Ratio[cut]\n",
    "        events.cscRechitCluster_match_MB1_0p4 = events.cscRechitCluster_match_MB1_0p4[cut]\n",
    "        events.cscRechitClusterMuonVetoPhi = events.cscRechitClusterMuonVetoPhi[cut]\n",
    "        events.cscRechitClusterTimeWeighted = events.cscRechitClusterTimeWeighted[cut]\n",
    "        events.cscRechitCluster_match_dtRechits_0p4 = events.cscRechitCluster_match_dtRechits_0p4[cut]\n",
    "        events.cscRechitCluster_match_MB1Seg_0p4 = events.cscRechitCluster_match_MB1Seg_0p4[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus41 = events.cscRechitClusterNRechitChamberMinus41[cut]\n",
    "        events.cscRechitClusterMajorAxis = events.cscRechitClusterMajorAxis[cut]\n",
    "        events.cscRechitClusterTimeSpreadWeightedAll = events.cscRechitClusterTimeSpreadWeightedAll[cut]\n",
    "        events.cscRechitClusterMuonVetoGlobal = events.cscRechitClusterMuonVetoGlobal[cut]\n",
    "        events.cscRechitClusterJetVetoPt = events.cscRechitClusterJetVetoPt[cut]\n",
    "        events.cscRechitCluster_match_RB1_0p4 = events.cscRechitCluster_match_RB1_0p4[cut]\n",
    "        events.cscRechitClusterJetVetoPhi = events.cscRechitClusterJetVetoPhi[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus11 = events.cscRechitClusterNRechitChamberPlus11[cut]\n",
    "        events.cscRechitClusterMuonVetoLooseId = events.cscRechitClusterMuonVetoLooseId[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus41 = events.cscRechitClusterNRechitChamberPlus41[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus31 = events.cscRechitClusterNRechitChamberMinus31[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus22 = events.cscRechitClusterNRechitChamberMinus22[cut]\n",
    "        events.cscRechitClusterTimeSpreadWeighted = events.cscRechitClusterTimeSpreadWeighted[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus21 = events.cscRechitClusterNRechitChamberMinus21[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus32 = events.cscRechitClusterNRechitChamberPlus32[cut]\n",
    "        events.cscRechitClusterPhiSpread = events.cscRechitClusterPhiSpread[cut]\n",
    "        events.cscRechitClusterDeltaRSpread = events.cscRechitClusterDeltaRSpread[cut]\n",
    "        events.cscRechitClusterX = events.cscRechitClusterX[cut]\n",
    "        events.cscRechitCluster_match_dtSeg_0p4 = events.cscRechitCluster_match_dtSeg_0p4[cut]\n",
    "        events.cscRechitClusterXYSpread = events.cscRechitClusterXYSpread[cut]\n",
    "        events.cscRechitClusterMaxStation = events.cscRechitClusterMaxStation[cut]\n",
    "        events.cscRechitClusterNStation = events.cscRechitClusterNStation[cut]\n",
    "        events.cscRechitCluster_match_cscRechits_0p4 = events.cscRechitCluster_match_cscRechits_0p4[cut]\n",
    "        events.cscRechitClusterPhi = events.cscRechitClusterPhi[cut]\n",
    "        events.cscRechitClusterMaxChamberRatio = events.cscRechitClusterMaxChamberRatio[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus42 = events.cscRechitClusterNRechitChamberMinus42[cut]\n",
    "        events.cscRechitCluster_match_dtRechits_phi0p2 = events.cscRechitCluster_match_dtRechits_phi0p2[cut]\n",
    "        events.cscRechitClusterRSpread = events.cscRechitClusterRSpread[cut]\n",
    "        events.cscRechitClusterAvgStation = events.cscRechitClusterAvgStation[cut]\n",
    "        events.cscRechitClusterNChamber = events.cscRechitClusterNChamber[cut]\n",
    "        events.cscRechitClusterEtaPhiSpread = events.cscRechitClusterEtaPhiSpread[cut]\n",
    "        events.cscRechitClusterMaxStationRatio = events.cscRechitClusterMaxStationRatio[cut]\n",
    "        events.cscRechitClusterMetEENoise_dPhi = events.cscRechitClusterMetEENoise_dPhi[cut]\n",
    "        events.cscRechitClusterJetVetoE = events.cscRechitClusterJetVetoE[cut]\n",
    "        events.cscRechitClusterMaxChamber = events.cscRechitClusterMaxChamber[cut]\n",
    "        events.cscRechitClusterNStation10 = events.cscRechitClusterNStation10[cut]\n",
    "        events.cscRechitClusterZ = events.cscRechitClusterZ[cut]\n",
    "        events.cscRechitClusterTimeSpread = events.cscRechitClusterTimeSpread[cut]\n",
    "        events.cscRechitClusterAvgStation5 = events.cscRechitClusterAvgStation5[cut]\n",
    "        events.cscRechitClusterXSpread = events.cscRechitClusterXSpread[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus13 = events.cscRechitClusterNRechitChamberPlus13[cut]\n",
    "        events.cscRechitClusterZSpread = events.cscRechitClusterZSpread[cut]\n",
    "        events.cscRechitClusterGenMuonDeltaR = events.cscRechitClusterGenMuonDeltaR[cut]\n",
    "        events.cscRechitClusterY = events.cscRechitClusterY[cut]\n",
    "        events.cscRechitClusterEta = events.cscRechitClusterEta[cut]\n",
    "        events.cscRechitClusterNStation5 = events.cscRechitClusterNStation5[cut]\n",
    "        events.cscRechitClusterTimeTotal = events.cscRechitClusterTimeTotal[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus22 = events.cscRechitClusterNRechitChamberPlus22[cut]\n",
    "        events.cscRechitClusterMuonVetoE = events.cscRechitClusterMuonVetoE[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus12 = events.cscRechitClusterNRechitChamberMinus12[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus31 = events.cscRechitClusterNRechitChamberPlus31[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus32 = events.cscRechitClusterNRechitChamberMinus32[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus12 = events.cscRechitClusterNRechitChamberPlus12[cut]\n",
    "        events.cscRechitClusterMuonVetoEta = events.cscRechitClusterMuonVetoEta[cut]\n",
    "        events.cscRechitClusterNRechitChamberPlus42 = events.cscRechitClusterNRechitChamberPlus42[cut]\n",
    "        events.cscRechitClusterMuonVetoPt = events.cscRechitClusterMuonVetoPt[cut]\n",
    "        events.cscRechitClusterJetVetoEta = events.cscRechitClusterJetVetoEta[cut]\n",
    "        events.cscRechitClusterMinorAxis = events.cscRechitClusterMinorAxis[cut]\n",
    "        events.cscRechitClusterAvgStation10 = events.cscRechitClusterAvgStation10[cut]\n",
    "        events.cscRechitClusterTime = events.cscRechitClusterTime[cut]\n",
    "        events.cscRechitClusterNRechitChamberMinus13 = events.cscRechitClusterNRechitChamberMinus13[cut]\n",
    "        events.cscRechitCluster_match_RE12_0p4 = events.cscRechitCluster_match_RE12_0p4[cut]   \n",
    "        \n",
    "        return events[ak.any(cut, axis = 1)]\n",
    "        '''\n",
    "    \n",
    "    def muonCutter(self, events, cut): \n",
    "        '''reads: \n",
    "        First cut all the muons in all events.\n",
    "        If there are no muons left, cut the whole event for all fields\n",
    "        '''\n",
    "        #print('before:',events.muonPt) #prints what muonPt's are before a cut\n",
    "        events.muonE = events.muonE[cut]\n",
    "        events.muonPt = events.muonPt[cut]\n",
    "        events.muonEta = events.muonEta[cut]\n",
    "        events.muonPhi = events.muonPhi[cut]\n",
    "        events.muonPdgId = events.muonPdgId[cut]\n",
    "        events.muonDZ = events.muonDZ[cut]\n",
    "        events.muonLooseId = events.muonLooseId[cut]\n",
    "        events.muonTightId = events.muonTightId[cut]\n",
    "        #print('after:', events.muonPt) #prints what muonPt's are after cut. You can see that it works here just fine.\n",
    "        #print(ak.any(cut, axis = 1)) #makes a boolean, 1D vector, where each element is true if any elements of a given event are true.\n",
    "        events = events[ak.any(cut, axis = 1)] #now this cut cuts all events where there are no muons left. \n",
    "        #print(events.muonPt) #you'll notice that it reverts back to what it was before the lead cut was made\n",
    "        return events[ak.any(cut, axis = 1)]\n",
    "    \n",
    "    \"\"\"\n",
    "    def deltaRPhiEtaCutter(self, events, cut): \n",
    "        '''reads: \n",
    "        First cut all the delta_s in all events.\n",
    "        If there are no muons left, cut the whole event for all fields.\n",
    "        '''        \n",
    "        events.deltaR_muon_cls = events.deltaR_muon_cls[cut]\n",
    "        events.deltaPhi_muon_cls = events.deltaPhi_muon_cls[cut]\n",
    "        events.deltaEta_muon_cls = events.deltaEta_muon_cls [cut]   \n",
    "        events = self.cscCutter(events, cut)\n",
    "        \n",
    "        return events[ak.any(cut, axis=1)]\n",
    "     \"\"\"\n",
    "    \n",
    "    def muon_acc_cut(self, events):\n",
    "        cut = (ak.count(events.muonPhi, axis=1) > 0)\n",
    "        #note that this works properly. \"cut\" here is the same shape as \"ak.any(cut, axis = 1)\" in \"muonCutter\"\n",
    "        return events[cut]\n",
    "    \n",
    "    def lead_muon_cut(self, events):\n",
    "        cut = ak.max(events.muonPt, axis=1) == events.muonPt #picks the greatest value in each event. (axis=0 means outermost array, axis=1 means next level of arrays)\n",
    "        return self.muonCutter(events, cut) #sends this cut to be applied to all muon variables.\n",
    "    \n",
    "    '''def llp_acc_cut(self, events):\n",
    "        if events.metadata['dataset'] == 'signal':\n",
    "            cut = (events.gLLP_csc == 1)\n",
    "            return events[cut]\n",
    "        else:\n",
    "            return events\n",
    "\n",
    "    def deltaRPhiEta_muon_cls(self, events):\n",
    "        clusts = ak.zip(\n",
    "            {\n",
    "                'pt': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "                'phi': events.cscRechitClusterPhi,\n",
    "                'eta': events.cscRechitClusterEta,\n",
    "                'E': ak.zeros_like(events.cscRechitClusterPhi),\n",
    "            },\n",
    "            with_name = 'PtEtaPhiMLorentzVector',\n",
    "            behavior = vector.behavior,                 \n",
    "          )\n",
    "        \n",
    "        muons = ak.zip(\n",
    "            {\n",
    "                'pt': events.muonPt,\n",
    "                'phi': events.muonPhi,\n",
    "                'eta': events.muonEta,\n",
    "                'E': events.muonE,\n",
    "            },\n",
    "            with_name = 'PtEtaPhiMLorentzVector',\n",
    "            behavior = vector.behavior,                 \n",
    "          )\n",
    "        \n",
    "        muon_cls_pairs = ak.cartesian({\n",
    "            \"clusts\": clusts, \n",
    "            \"muons\": muons\n",
    "        })\n",
    "        \n",
    "        deltaR = (muon_cls_pairs.clusts).delta_r(muon_cls_pairs.muons)\n",
    "        deltaEta = abs(muon_cls_pairs.clusts.eta - muon_cls_pairs.muons.eta)\n",
    "        deltaPhi = np.arctan2(np.sin(muon_cls_pairs.clusts.phi - muon_cls_pairs.muons.phi), \n",
    "                              np.cos(muon_cls_pairs.clusts.phi - muon_cls_pairs.muons.phi))\n",
    "        \n",
    "        \n",
    "        for i in range(len(deltaR)):\n",
    "            if i in [4579,15785,19586,26798,28666]:\n",
    "                print(f'no muons| muon.phi: {muons.phi[i]}, deltaR: {deltaR[i]}, clusterZ {events.cscRechitClusterZ[i]}')\n",
    "            if i in range(25):\n",
    "                print(f'muons| muon.phi: {muons.phi[i]}, deltaR: {deltaR[i]}, clusterZ {events.cscRechitClusterZ[i]}')\n",
    "        \n",
    "        \n",
    "        return deltaR, deltaPhi, deltaEta\n",
    "    \n",
    "    def deltaR_muon_cls_cut(self, events):\n",
    "        \n",
    "        \n",
    "        cut = events.deltaR_muon_cls > 1.\n",
    "        return self.deltaRPhiEtaCutter(events, cut)\n",
    "    '''\n",
    "    \n",
    "    def process(self, events):\n",
    "        \n",
    "        #this block here is for convenience. It adds muon branches, filtered from leptons\n",
    "        muoncut = abs(events.lepPdgId == 13)\n",
    "        events['muonE'] = events.lepE[muoncut]\n",
    "        events['muonPt'] = events.lepPt[muoncut]\n",
    "        events['muonEta'] = events.lepEta[muoncut]\n",
    "        events['muonPhi'] = events.lepPhi[muoncut]\n",
    "        events['muonPdgId'] = events.lepPdgId[muoncut]\n",
    "        events['muonDZ'] = events.lepDZ[muoncut]\n",
    "        events['muonLooseId'] = events.lepLooseId[muoncut]\n",
    "        events['muonTightId'] = events.lepTightId[muoncut]\n",
    "        \n",
    "        # the goal of this little block is to remove events with no muons,\n",
    "        # and then remove all muons that aren't the lead muon.\n",
    "        print('nothing:', events.muonPt)       \n",
    "        events = self.muon_acc_cut(events)\n",
    "        print('muon_acc_cut:', events.muonPt)       \n",
    "        events = self.lead_muon_cut(events)\n",
    "        print('lead_muon_cut:', events.muonPt)\n",
    "\n",
    "        \n",
    "        \n",
    "        #events = self.llp_acc_cut(events)\n",
    "        \n",
    "        '''\n",
    "        deltaR_muon_cls, deltaPhi_muon_cls, deltaEta_muon_cls = self.deltaRPhiEta_muon_cls(events)\n",
    "        events['deltaR_muon_cls'] = deltaR_muon_cls\n",
    "        events['deltaPhi_muon_cls'] = deltaPhi_muon_cls\n",
    "        events['deltaEta_muon_cls'] = deltaEta_muon_cls\n",
    "        '''\n",
    "        \n",
    "        dataset = events.metadata['dataset']\n",
    "        out = {\n",
    "            dataset: {\n",
    "                \"entries\": len(events),\n",
    "            },\n",
    "            #\"cuts\": {},\n",
    "            #\"vars\": {},\n",
    "\n",
    "        }\n",
    "        \n",
    " \n",
    "        return out   \n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "date = today.strftime(\"%m_%d_%y\")\n",
    "\n",
    "fileset = {}\n",
    "fileset['signal']     = ['root://cmsxrootd.fnal.gov//store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_Fall18/v2/v3/normalized/BToKPhi_MuonGenFilter_mPhi1p0_ctau1000_1pb_weighted.root',]\n",
    "#fileset['background'] = ['root://cmsxrootd.fnal.gov//store/user/christiw/displacedJetMuonAnalyzer/csc/V1p171/Data2018_UL/v3/normalized/ParkingBPH4_Run2018A_goodLumi.root']\n",
    "out = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    treename=\"MuonSystem\",\n",
    "    processor_instance=LLP_ntuple_processor(),\n",
    "    executor=processor.futures_executor,\n",
    "    executor_args={\"schema\": BaseSchema, \"workers\": 1},\n",
    "    maxchunks = 1\n",
    ")\n",
    "\n",
    "#cuts = list(out['cuts'].keys())\n",
    "#varnames = list(out['vars'].keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "    def csc_eff_cut(self, events):\n",
    "        \n",
    "        cut = (events.nCscRechitClusters >= 1)\n",
    "        return events[cut]\n",
    "    \n",
    "    def met_cut(self, events):\n",
    "        cut = events.metEENoise >= 30\n",
    "        return events[cut]\n",
    "\n",
    "    def muon_veto(self, events):\n",
    "        \n",
    "        cut = (events.cscRechitClusterMuonVetoPt < 20)\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "\n",
    "    def jet_cut(self, events):\n",
    "        \n",
    "        cut = (events.cscRechitClusterJetVetoPt < 10)\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "\n",
    "    def time_cut(self, events):\n",
    "\n",
    "        cut = ((events.cscRechitClusterTimeWeighted <= 12.5)&\n",
    "               (events.cscRechitClusterTimeWeighted >= -5  ))\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "\n",
    "    def ME11_veto(self, events):\n",
    "        cut = ((events.cscRechitClusterNRechitChamberPlus11 <= 0)&\n",
    "               (events.cscRechitClusterNRechitChamberMinus11 <= 0))\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "\n",
    "\n",
    "    def ME12_veto(self, events):\n",
    "\n",
    "        cut = ((events.cscRechitClusterNRechitChamberPlus12 <= 0)&\n",
    "               (events.cscRechitClusterNRechitChamberMinus12 <= 0))\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "\n",
    "\n",
    "    def re12_cut(self, events):\n",
    "        \n",
    "        cut = events.cscRechitCluster_match_RE12_0p4 == 0\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "\n",
    "    def mb1_cut(self, events):\n",
    "        \n",
    "        cut = events.cscRechitCluster_match_MB1Seg_0p4 == 0\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "    def rb1_cut(self, events):\n",
    "        \n",
    "        cut = events.cscRechitCluster_match_RB1_0p4 == 0\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "    def llp_eta_cut(self, events):\n",
    "        if events.metadata['dataset'] == 'signal':\n",
    "            cut = abs(events.gLLP_eta) < 2 \n",
    "            return events[cut]\n",
    "        else:\n",
    "            return events\n",
    "\n",
    "    def time_spread_cut(self, events):\n",
    "    \n",
    "        cut = events.cscRechitClusterTimeSpreadWeightedAll <= 20\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "    def cls_eta_cut(self, events):\n",
    "        \n",
    "        cut = abs(events.cscRechitClusterEta) < 1.9\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "    def cls_size_cut(self, events):\n",
    "        \n",
    "        cut = events.cscRechitClusterSize > 100\n",
    "        return self.cscCutter(events, cut)\n",
    "    \n",
    "    \n",
    "    def cut_based(self, events):\n",
    "    \n",
    "        cut = (((events.cscRechitClusterNStation10 > 1) & (abs(events.cscRechitClusterEta) < 1.9))|\n",
    "               ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 4) & (abs(events.cscRechitClusterEta) < 1.8))|\n",
    "               ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 3) & (abs(events.cscRechitClusterEta) < 1.6))|\n",
    "               ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 2) & (abs(events.cscRechitClusterEta) < 1.6))|\n",
    "               ((events.cscRechitClusterNStation10 == 1) & (abs(events.cscRechitClusterAvgStation10) == 1) & (abs(events.cscRechitClusterEta) < 1.1))\n",
    "            )\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "    def dphi_cut(self, events):\n",
    "    \n",
    "        cut = abs(events.cscRechitClusterMetEENoise_dPhi) < 0.75\n",
    "        return self.cscCutter(events, cut)\n",
    "\n",
    "    def nrechits_cut(self, events):\n",
    "\n",
    "        cut = events.cscRechitClusterSize > 130\n",
    "        return self.cscCutter(events, cut)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "       # cheeky way of sequentially adding cuts to events\n",
    "        #cuts = [self.acc_cut, self.csc_eff_cut, self.met_cut, self.muon_veto, self.jet_cut, self.time_cut, self.ME11_veto, self.ME12_veto, self.re12_cut, self.mb1_cut, self.rb1_cut, self.eta_cut, self.time_spread_cut, self.cut_based, self.dphi_cut, self.nrechits_cut]\n",
    "        #cuts = [self.acc_cut, self.ME11_veto, self.ME12_veto, self.re12_cut, self.mb1_cut, self.rb1_cut, self.deltaR_muon_cls_cut]\n",
    "        cuts = [self.csc_eff_cut,\n",
    "                self.ME11_veto, self.ME12_veto, self.re12_cut, self.mb1_cut, self.rb1_cut,\n",
    "                self.deltaR_muon_cls_cut, \n",
    "                self.time_cut, self.cls_eta_cut, self.cls_size_cut]\n",
    "        \n",
    "        \n",
    "        _ = lambda x: x\n",
    "        \n",
    "        bins = 30\n",
    "        vrbls = {\n",
    "            'met':               [bins,    0, 100, _,   'metEENoise'],\n",
    "            'dphi':              [bins,    0,   5, _,   'cscRechitClusterMetEENoise_dPhi'],\n",
    "            'timeSpread':        [bins,    0,  20, _,   'cscRechitClusterTimeSpreadWeightedAll'],\n",
    "            'clsTimeWeighted':   [bins, -5.5,  13, _,   'cscRechitClusterTimeWeighted'],\n",
    "            'clsSize':           [bins,    0, 130, _,   'cscRechitClusterSize'],\n",
    "            'clsEta':            [bins,    0,   4, abs, 'cscRechitClusterEta'],\n",
    "            'NStation10':        [bins,  -10,  10, _,   'cscRechitClusterNStation10'],\n",
    "            'AvgStation10':      [bins,  -10,  10, _,   'cscRechitClusterAvgStation10'],\n",
    "            #'deltaR_muon_cls':   [bins,    0,   4, _,   'cscRechitCluster_deltaR_muon_cls'],\n",
    "            #'deltaEta_muon_cls': [bins,    0,   4, _,   'cscRechitCluster_deltaPhi_muon_cls'],\n",
    "            #'deltaPhi_muon_cls': [bins,    0,   4, _,   'cscRechitCluster_deltaEta_muon_cls'],\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        last = events\n",
    "        def histsaver(out: dict, last, cut: str):\n",
    "            \n",
    "            out['cuts'][cut] = 1 #dummy\n",
    "            out[dataset][cut] = len(last)\n",
    "            \n",
    "            # I need to improve this block of code, this is aweful\n",
    "            #vrbls['deltaR_muon_cls'][4], vrbls['deltaEta_muon_cls'][4], vrbls['deltaPhi_muon_cls'][4] = self.muon_cls_deltaR(last)\n",
    "            #vrbls['deltaR_muon_cls'][5] = vrbls['deltaR_muon_cls'][4] > 1.\n",
    "            #vrbls['deltaEta_muon_cls'][5] = vrbls['deltaEta_muon_cls'][4] > -10 #these are dummy bools\n",
    "            #vrbls['deltaPhi_muon_cls'][5] = vrbls['deltaPhi_muon_cls'][4] > -10\n",
    "            \n",
    "            for var in vrbls:\n",
    "                out['vars'][var] = 1 #dummy\n",
    "                v = vrbls[var]\n",
    "                '''\n",
    "                if var.startswith('delta'):\n",
    "                                  \n",
    "                    out[dataset][f'{cut}_{var}'] = hs.Hist.new.Reg(v[0], v[1], v[2], name=var, label=var).Double()\n",
    "                    out[dataset][f'{cut}_{var}'].fill(ak.flatten(v[3](v[4][v[5]]), axis=None))                    \n",
    "                else:'''\n",
    "                out[dataset][f'{cut}_{var}'] = hs.Hist.new.Reg(v[0], v[1], v[2], name=var, label=var).Double()\n",
    "                out[dataset][f'{cut}_{var}'].fill(ak.flatten(v[3](last[v[4]]), axis=None))\n",
    "            \n",
    "            #~~~~~~~\n",
    "\n",
    "            '''out[dataset][f'{cut}_deltaR_muon_cls'] = hs.Hist.new.Reg(30, 0, 4, name='deltaR_muon_cls', label='deltaR_muon_cls').Double()\n",
    "            out[dataset][f'{cut}_deltaEta_muon_cls'] = hs.Hist.new.Reg(30, 0, 4, name='deltaEta_muon_cls', label='deltaEta_muon_cls').Double()\n",
    "            out[dataset][f'{cut}_deltaPhi_muon_cls'] = hs.Hist.new.Reg(30, 0, 4, name='deltaPhi_muon_cls', label='deltaPhi_muon_cls').Double()\n",
    "            \n",
    "            out[dataset][f'{cut}_deltaR_muon_cls'].fill(ak.flatten(deltaR_muon_cls.mask[clsCuts], axis=None))\n",
    "            out[dataset][f'{cut}_deltaEta_muon_cls'].fill(ak.flatten(deltaR_muon_cls.mask[clsCuts], axis=None))\n",
    "            out[dataset][f'{cut}_deltaPhi_muon_cls'].fill(ak.flatten(deltaR_muon_cls.mask[clsCuts], axis=None))'''\n",
    "\n",
    "            #~~~~~~~\n",
    "            '''\n",
    "            if dataset == 'signal':\n",
    "                out[dataset][f'{cut}_deltaR_llp_cls'] = hs.Hist.new.Reg(30, 0, 4, name='deltaR_llp_cls', label='deltaR_llp_cls').Double()\n",
    "                out[dataset][f'{cut}_deltaEta_llp_cls'] = hs.Hist.new.Reg(30, 0, 4, name='deltaEta_llp_cls', label='deltaEta_llp_cls').Double()\n",
    "                out[dataset][f'{cut}_deltaPhi_llp_cls'] = hs.Hist.new.Reg(30, 0, 4, name='deltaPhi_llp_cls', label='deltaPhi_llp_cls').Double()\n",
    "\n",
    "                out[dataset][f'{cut}_deltaR_llp_cls'].fill(ak.flatten(deltaR_llps_cls.mask[clsCuts], axis=None))\n",
    "                out[dataset][f'{cut}_deltaEta_llp_cls'].fill(ak.flatten(deltaEta_llps_cls.mask[clsCuts], axis=None))\n",
    "                out[dataset][f'{cut}_deltaPhi_llp_cls'].fill(ak.flatten(deltaPhi_llps_cls.mask[clsCuts], axis=None))'''\n",
    "            \n",
    "            #~~~~~~~\n",
    "            '''\n",
    "            out[dataset][f'{cut}_clsEta_NStation==1'] = hs.Hist.new.Reg(30, 0, 4, name='clsEta', label='eta').Double() \n",
    "            out[dataset][f'{cut}_NStation10_NStation==1'] = hs.Hist.new.Reg(30, -10, 10, name='NStation10', label='NStation10').Double()            \n",
    "            out[dataset][f'{cut}_AvgStation10_NStation==1'] = hs.Hist.new.Reg(30, -10, 10, name='AvgStation10', label='AvgStation10').Double()               \n",
    "            out[dataset][f'{cut}_clsEta_NStation>1'] = hs.Hist.new.Reg(30, 0, 4, name='clsEta', label='eta').Double()  \n",
    "            out[dataset][f'{cut}_NStation10_NStation>1'] = hs.Hist.new.Reg(30, -10, 10, name='NStation10', label='NStation10').Double()            \n",
    "            out[dataset][f'{cut}_AvgStation10_NStation>1'] = hs.Hist.new.Reg(30, -10, 10, name='AvgStation10', label='AvgStation10').Double()   \n",
    "            \n",
    "            specialCuts = clsCuts & (last.cscRechitClusterNStation10 == 1)\n",
    "            out[dataset][f'{cut}_clsEta_NStation==1'].fill(ak.flatten(abs(last.cscRechitClusterEta.mask[specialCuts]), axis=None)) \n",
    "            out[dataset][f'{cut}_NStation10_NStation==1'].fill(ak.flatten(last.cscRechitClusterNStation10.mask[specialCuts], axis=None))\n",
    "            out[dataset][f'{cut}_AvgStation10_NStation==1'].fill(ak.flatten(last.cscRechitClusterAvgStation10.mask[specialCuts], axis=None))   \n",
    "            specialCuts = clsCuts & (last.cscRechitClusterNStation10 > 1)\n",
    "            out[dataset][f'{cut}_clsEta_NStation>1'].fill(ak.flatten(abs(last.cscRechitClusterEta.mask[specialCuts]), axis=None))      \n",
    "            out[dataset][f'{cut}_NStation10_NStation>1'].fill(ak.flatten(last.cscRechitClusterNStation10.mask[specialCuts], axis=None))\n",
    "            out[dataset][f'{cut}_AvgStation10_NStation>1'].fill(ak.flatten(last.cscRechitClusterAvgStation10.mask[specialCuts], axis=None)) '''\n",
    " \n",
    "     \n",
    "            \n",
    "        histsaver(out, last, 'total')\n",
    "        \n",
    "        for cut in cuts:\n",
    "            print('\\t'+cut.__name__)\n",
    "            last = cut(last)\n",
    "            print()\n",
    "\n",
    "                \n",
    "            histsaver(out, last, cut.__name__)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cut in cuts:\n",
    "    h = out['signal'][cut]\n",
    "    print(f'{cut}, {h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from hist.intervals import ratio_uncertainty\n",
    "def ratio(num, den, ax):\n",
    "    ax.errorbar(\n",
    "        x=num.axes[0].centers,\n",
    "        y=num.view() / den.view() ,\n",
    "        yerr=ratio_uncertainty(num.view(), den.view()),\n",
    "        color=\"k\",\n",
    "        linestyle=\"none\",\n",
    "        marker=\"o\",\n",
    "        elinewidth=1,\n",
    "    )\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings(): #i don't need to see all the divide by zero warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    for varname in varnames:\n",
    "        #pdf = PdfPages(f'varPlots_sb_clsCuts_{date}/{varname}_cutflow_sb.pdf')\n",
    "\n",
    "        for cut in cuts:\n",
    "            fig, ax = plt.subplots(2,1, gridspec_kw={'height_ratios': [3, 1]}, figsize=(np.sqrt(2)*5,5))\n",
    "\n",
    "            signal = out['signal'][f'{cut}_{varname}']\n",
    "            background = out['background'][f'{cut}_{varname}']\n",
    "\n",
    "            hep.histplot(signal/signal.sum(), label='signal', ax=ax[0])\n",
    "            hep.histplot(background/background.sum(), label='background', ax=ax[0])\n",
    "            ax[0].set_title(f'{varname} with {cut} cut')\n",
    "            ax[0].legend()\n",
    "            ax[0].tick_params(\n",
    "                axis='x',          # changes apply to the x-axis\n",
    "                which='both',      # both major and minor ticks are affected\n",
    "                bottom=False,      # ticks along the bottom edge are off\n",
    "                top=False,         # ticks along the top edge are off\n",
    "                labelbottom=False) # labels along the bottom edge are off\n",
    "            ax[0].set(xlabel=None)\n",
    "            ax[0].set_yscale('log')\n",
    "\n",
    "            ratio(signal/signal.sum(), background/background.sum(), ax[1])\n",
    "            ax[1].set_xlim(ax[0].get_xlim())\n",
    "            ax[1].set(xlabel=varname)\n",
    "            ax[1].set_yscale('log')\n",
    "            fig.subplots_adjust(wspace=0, hspace=.05)\n",
    "            #pdf.savefig(fig)\n",
    "        #pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings(): #i don't need to see all the divide by zero warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    varnames = ['deltaR_llp_cls', 'deltaEta_llp_cls', 'deltaPhi_llp_cls',]\n",
    "\n",
    "    for varname in varnames:\n",
    "        pdf = PdfPages(f'deltaREtaPhi_llp_cls_ss_{date}/{varname}_cutflow_sb.pdf')\n",
    "\n",
    "        for cut in cuts:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "            signal = out['signal'][f'{cut}_{varname}']\n",
    "\n",
    "            hep.histplot(signal, label='signal', ax=ax)\n",
    "            ax.set_title(f'{varname} with {cut} cut')\n",
    "            ax.set_yscale('log')\n",
    "            pdf.savefig(fig)\n",
    "        pdf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = out['signal']['rb1_cut_deltaR_llp_cls']\n",
    "h[1.j:].sum()/h.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
