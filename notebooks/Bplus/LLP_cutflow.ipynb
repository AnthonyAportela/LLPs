{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import hist as hs\n",
    "from coffea import processor, hist as chs\n",
    "from coffea.nanoevents.methods import vector, candidate\n",
    "from numba import jit\n",
    "\n",
    "from coffea.nanoevents import BaseSchema\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(hep.style.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLP_ntuple_processor(processor.ProcessorABC):\n",
    "    \"\"\"\n",
    "    This class is used to process the ntuples created by the LLP ntuple producer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # create a dictionary for storing dimensions of different parts of the detector\n",
    "        self.detector_dimensions = {\n",
    "            'csc': {},\n",
    "            'dt': {},\n",
    "            'cms': {},\n",
    "        }\n",
    "\n",
    "        # fill detector_dimensions with the dimensions of the different parts of the detector\n",
    "        s = 1e2  # scale factor\n",
    "        self.detector_dimensions['csc']['zmin'] = s * 5.5\n",
    "        self.detector_dimensions['csc']['zmax'] = s * 10.\n",
    "        self.detector_dimensions['csc']['rmin'] = s * 0.\n",
    "        self.detector_dimensions['csc']['rmax'] = s * 7.\n",
    "        self.detector_dimensions['dt']['zmin'] = s * 0.\n",
    "        self.detector_dimensions['dt']['zmax'] = s * 6.5\n",
    "        self.detector_dimensions['dt']['rmin'] = s * 4.\n",
    "        self.detector_dimensions['dt']['rmax'] = s * 7.5\n",
    "\n",
    "        self.detector_dimensions['cms']['zmin'] = s * 0.\n",
    "        self.detector_dimensions['cms']['zmax'] = s * 16.\n",
    "        self.detector_dimensions['cms']['rmin'] = s * 0.\n",
    "        self.detector_dimensions['cms']['rmax'] = s * 12.\n",
    "\n",
    "    def llp_cut(self, events, pid):\n",
    "        \"\"\"\n",
    "        this function will filter events that have gLLPs\n",
    "        :param events:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        cut = events.gParticleId == pid\n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "\n",
    "    def muon_pt_cut(self, events, pid):\n",
    "        \n",
    "        llp_mother_index = ak.flatten(events.gParticleMotherIndex[events.gParticleId == pid], axis=None)\n",
    "        cut = events.gParticlePt[(events.gParticleMotherIndex == llp_mother_index[:,None]) & \n",
    "                                 (abs(events.gParticleId) == 13)] > 9\n",
    "\n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "    def muon_eta_cut(self, events, pid):\n",
    "        \n",
    "        llp_mother_index = ak.flatten(events.gParticleMotherIndex[events.gParticleId == pid], axis=None)\n",
    "        cut = abs(events.gParticleEta[(events.gParticleMotherIndex == llp_mother_index[:,None]) & \n",
    "                                 (abs(events.gParticleId) == 13)]) < 1.5\n",
    "\n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "    def csc_cut(self, events, pid):\n",
    "        \"\"\"\n",
    "        this function will filter events that have gLLPs within the CSC\n",
    "        :param events:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # we need the decay vertices of the llps but events doesn't have that information. but we do have access to\n",
    "        # the id of the mother particles (gParticleMotherId) as well as production vertices of all particles (\n",
    "        # gParticleProdVertexX, gParticleProdVertexY, gParticleProdVertexZ) Make a mask of the particles whose mother\n",
    "        # is the llp\n",
    "        mother_llp_mask = events.gParticleMotherId == pid\n",
    "        # However, each llp will have multiple products, so events.gParticleProdVertexX[mother_llp_mask] will have\n",
    "        # duplicates To remove the duplicates we can use a trick that uses ak.argmax to find the index of the first\n",
    "        # occurrence of each truth value Make an awkward array of the indices of the first occurrence of each truth\n",
    "        # value within the second level of the mask\n",
    "        llp_daughter_index = ak.argmax(mother_llp_mask, axis=1, keepdims=True)\n",
    "        # Now we can use llp_daughter_index to get the indexes of the llps themselves using gParticleMotherIndex\n",
    "        llp_index = events.gParticleMotherIndex[llp_daughter_index]\n",
    "\n",
    "        def R(x, y):\n",
    "            return np.sqrt(x ** 2 + y ** 2)\n",
    "\n",
    "        dims = self.detector_dimensions['csc']\n",
    "        cut = (\n",
    "                (abs(events.gParticleEta) < 2.4) &\n",
    "                (abs(events.gParticleProdVertexZ) > dims['zmin']) & (abs(events.gParticleProdVertexZ) < dims['zmax']) &\n",
    "                (R(events.gParticleProdVertexX, events.gParticleProdVertexX) < dims['rmax'])\n",
    "        )\n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "    def timetotal_cut(self, events, pid):\n",
    "        cut = ((events.cscRechitClusterTimeTotal >= -5) & \n",
    "               (events.cscRechitClusterTimeTotal <= 12.5))\n",
    "        \n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "    def ME1112_veto(self, events, pid):\n",
    "        cut = (\n",
    "                (events.cscRechitClusterNRechitChamberPlus11 <= 0) &\n",
    "                (events.cscRechitClusterNRechitChamberPlus12 <= 0) &\n",
    "                (events.cscRechitClusterNRechitChamberMinus11 <= 0) &\n",
    "                (events.cscRechitClusterNRechitChamberMinus12 <= 0)\n",
    "        )\n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "    def eta_cut(self, events, pid): \n",
    "        cut = (abs(events.gParticleEta) < 2)\n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "    def timeSpread_cut(self, events, pid):\n",
    "        cut = (events.cscRechitClusterTimeSpread <= 20)\n",
    "        return events[ak.any(cut, axis = -1)]\n",
    "\n",
    "\n",
    "    def process(self, events):\n",
    "        \"\"\"\n",
    "        This function is used to do addition basically.\n",
    "        :param events:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        dataset = events.metadata['dataset']\n",
    "        sumw = ak.sum(events.genWeight)\n",
    "\n",
    "        out = {\n",
    "            dataset: {\n",
    "                \"entries\": len(events),\n",
    "                \"sumw\": sumw,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # simple if statement that assigns a variable 'pid' to 9900015 or 1000023 if any of the events has one of\n",
    "        # those particles\n",
    "        if ak.any(events.gParticleId == 9900015): pid = 9900015\n",
    "        if ak.any(events.gParticleId == 1000023): pid = 1000023\n",
    "\n",
    "        '''events_with_llps = self.llp_cut(events, pid)\n",
    "        muon_pt_cut = self.muon_pt_cut(events_with_llps, pid)\n",
    "        muon_eta_cut = self.muon_eta_cut(muon_pt_cut, pid)\n",
    "        csc_acc_cut = self.csc_cut(muon_eta_cut, pid)\n",
    "        csc_cls_cut = csc_acc_cut[csc_acc_cut.nCscRechitClusters >= 1]\n",
    "        timetotal_cut = self.timetotal_cut(csc_cls_cut, pid)\n",
    "        ME1112_veto = self.ME1112_veto(timetotal_cut, pid)\n",
    "        eta_cut = self.eta_cut(ME1112_veto, pid)\n",
    "        timeSpread_cut = self.timeSpread_cut(eta_cut, pid)\n",
    "    \n",
    "        out[dataset]['events_with_llps'] = len(events_with_llps)\n",
    "        out[dataset]['muon_pt_cut'] = len(muon_pt_cut)\n",
    "        out[dataset]['muon_eta_cut'] = len(muon_eta_cut)\n",
    "        out[dataset]['csc_cls_cut'] = len(csc_cls_cut)\n",
    "        out[dataset]['csc_acc_cut'] = len(csc_acc_cut)\n",
    "        out[dataset]['timetotal_cut'] = len(timetotal_cut)\n",
    "        out[dataset]['ME1112_veto'] = len(ME1112_veto)\n",
    "        out[dataset]['eta_cut'] = len(eta_cut)\n",
    "        out[dataset]['timeSpread_cut'] = len(timeSpread_cut)'''\n",
    "\n",
    "        events_with_llps = self.llp_cut(events, pid)\n",
    "        csc_acc_cut = self.csc_cut(events_with_llps, pid)\n",
    "        csc_cls_cut = csc_acc_cut[csc_acc_cut.nCscRechitClusters >= 1]\n",
    "        timetotal_cut = self.timetotal_cut(csc_cls_cut, pid)\n",
    "        ME1112_veto = self.ME1112_veto(timetotal_cut, pid)\n",
    "        eta_cut = self.eta_cut(ME1112_veto, pid)\n",
    "        timeSpread_cut = self.timeSpread_cut(eta_cut, pid)\n",
    "    \n",
    "        out[dataset]['events_with_llps'] = len(events_with_llps)\n",
    "        out[dataset]['csc_cls_cut'] = len(csc_cls_cut)\n",
    "        out[dataset]['csc_acc_cut'] = len(csc_acc_cut)\n",
    "        out[dataset]['timetotal_cut'] = len(timetotal_cut)\n",
    "        out[dataset]['ME1112_veto'] = len(ME1112_veto)\n",
    "        out[dataset]['eta_cut'] = len(eta_cut)\n",
    "        out[dataset]['timeSpread_cut'] = len(timeSpread_cut)\n",
    "             \n",
    "        return out\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aff8de482374ffdb9581c94d257cedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/599 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# digging up\n",
    "def rootAdds(directory):\n",
    "    my_file = open(directory, \"r\")\n",
    "    data = my_file.read().strip()\n",
    "    data_into_list = data.split(\"\\n\")\n",
    "    my_file.close()\n",
    "    return data_into_list\n",
    "\n",
    "fileset = {}\n",
    "fileset['hnl'] = rootAdds('notebooks/Bplus/rootAdds/BToHNL_MuonAndHNLGenFilter_mHNL1p0_ctau1000.txt')\n",
    "#fileset['phi'] = rootAdds('notebooks/Bplus/rootAdds/BToKPhi_MuonGenFilter_mPhi1p0_ctau1000.txt')\n",
    "\n",
    "out = processor.run_uproot_job(\n",
    "    fileset,\n",
    "    treename=\"ntuples/llp\",\n",
    "    processor_instance=LLP_ntuple_processor(),\n",
    "    executor=processor.futures_executor,\n",
    "    executor_args={\"schema\": BaseSchema, \"workers\": 6},\n",
    "    #maxchunks = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'events_with_llps': 173410,\n",
       " 'csc_cls_cut': 3181,\n",
       " 'timetotal_cut': 2734,\n",
       " 'timeSpread_cut': 707,\n",
       " 'csc_acc_cut': 13474,\n",
       " 'eta_cut': 733,\n",
       " 'ME1112_veto': 733,\n",
       " 'entries': 173410,\n",
       " 'sumw': 173410.0}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['hnl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
